#summary History of the Planarity Project up to Version 2.0
#labels Featured

by John Boyer

= Origin =

Early in my graduate studies (1996), I took a graph algorithms course from Wendy Myrvold, who later became my Ph.D. supervisor.  For my course project, I chose to study linear time planarity algorithms, which were widely regarded as being quite complex.  

The Lempel-Even-Cederbaum (LEC) planarity algorithm is a _vertex addition_ method that was optimized to linear time by the PQ-tree data structure created by Booth and Lueker. In a selected order, each vertex is added to a partial embedding, along with the edges incident to that new vertex and the vertices previously added to the partial embedding. The LEC algorithm relies for its correctness on adding vertices in the order produced by an _st_-numbering.

In an _st_-numbering, the first vertex _s_ is the source, the last vertex _t_ is the target, and every vertex in between has a path of lower numbered vertices leading back to _s_ and a path of higher numbered vertices leading to _t_.  The fact that all vertices have a path of lower numbered vertices back to _s_ means that a single PQ-tree can be used to manage the partial embedding as vertices are added. The fact that all vertices have a path of higher numbered vertices leading to _t_ means that, at each vertex step, the partial embedding can be manipulated so that all vertices with connections to unembedded vertices appear in a single face of the partial embedding.

The PQ-tree has many templates that characterize how to manipulate it, and a number of optimizations for how to detect and apply those template patterns efficiently.  I began to focus on the LEC algorithm over other planarity algorithms because it seemed that it might be possible to make a significant simplification.  I realized that a DFS tree taken from the bottom up had the key property needed for correctness, i.e. that all vertices had a path of ancestors to the root.  Not having a single source seemed only to introduce the need to handle a forest, but some PQ tree templates seemed to be unnecessary and others were simpler.

About a month after the course was over, Wendy contacted me and asked if I was going to pursue my project any further, and if not then could she pursue it independently.  Clearly, as a potential thesis topic, this project had legs. 

= Edge Addition: A New Planar Embedding Algorithm =

After a few meetings, Wendy and I had worked out the fact that we would work directly on a graph data structure that could manage biconnected components and whose vertices were equipped with extra data to manage planarity information of our algorithm. We defined an externally active vertex as one that had to remain on the external face as the current vertex is embedded, and we defined an internally active vertex as one to which an edge or biconnected component must be attached as part of embedding the current vertex.  We defined a _Walkup_ routine that would figure out how to flip biconnected components and take paths that avoided externally active vertices in order to embed the new vertex, and we defined a routine called _Walkdown_ that would simply use the path and flipping information collected by _Walkup_ to actually perform the vertex embedding.  Then, it was my job to go forth and make a full and complete project of it by sorting out all the details related to formally proving correctness and achieving linear time performance.

For correctness, a straightforward case analysis was possible based on all the possible path selections that could be made by the _Walkup_.  These _Walkup_ path selection rules were eventually published, and although they are simpler than PQ-tree manipulations, it has turned out to be possible to create a fundamentally new planarity algorithm whose implementation and proof of correctness does not rely on them by focusing on the _Walkdown_.  But we're getting ahead of the story.

For linear time performance, I felt it was best to create an implementation as a way to focus myself on all the details to ensure no aspect of performance considerations were missed.  As I did this, it became clear that the _Walkdown_ could incrementally make decisions about what paths to take and what biconnected components to flip as it embedded the individual edges between the vertex being embedded and its various DFS descendants already embedded.  The only reason for retaining the _Walkup_, it appeared, was to help identify the biconnected components pertinent for the _Walkdown_ to visit in order to embed edges.  

Not only did the new approach give a clear picture of how the partial embedding changed as a particular edge was embedded, but I also saw how to dynamically define the notions of internal activity and external activity as properties that could change in response to the addition of a single edge. It was clear that this had become an *edge addition* method. 

Although I had managed to implement this version by mid-1998, I had not yet created a formal proof of correctness.  The corresponding vertex addition method had more complicated path selection rules in the _Walkup_, but the path selection rules resulted from a tedious but straightforward case analysis.  It had still to be proven that this new edge addition approach, with it's very simple path selection rules in the _Walkdown_ and its dynamic external and internal activity, was correct based on more sophisticated analysis.  Hence, Wendy and I decided to report our vertex addition method is the [http://portal.acm.org/citation.cfm?id=314500.314545 SODA paper] that appeared in 1999, and I was promoted to the doctoral program with the plan of proceeding with this new approach to prove it correct and efficient and to create a full Kuratowski subgraph isolator (or a planarity obstruction isolator, which is finds a subgraph homeomorphic to K{3,3} or K5).  

That first implementation of combinatorial planar embedding and Kuratowski subgraph isolation, along with the proofs of correctness and linear time performance appearing in my dissertation in 2001, should be considered *version 1.0* of this planarity project.  The [http://jgaa.info/accepted/2004/BoyerMyrvold2004.8.3/planarity.zip source code for Planarity version 1.0] accompanies the [http://jgaa.info/accepted/2004/BoyerMyrvold2004.8.3.pdf paper in the Journal of Graph Algorithms and Applications].  

To thoroughly test this implementation, I used Brendan !McKay's nauty graph generator (_makeg_). For each connected graph of less than 12 vertices, the planar embedder was invoked, which resulted in either a combinatorial planar embedding or a Kuratowski subgraph.  Each result was then tested for integrity.  For a planar embedding, the integrity check ensured that the embedding has the correct number of faces according to Euler's formula, and it ensured that each edge is traversed twice during the counting.  For the non-planar case, the integrity check ensured that the result was in fact a subgraph of the input graph and that its structure was indeed that of a K{3,3} or K5 homeomorph.

= Planarity-Related Algorithms =

My dissertation also reported a number of planarity-related algorithms in addition to the core planar embedder and Kuratowski subgraph isolator.  

In the method that determines whether a vertex is _externally active_, simply changing the code to always return true yields a solution for _outerplanar graph embedding_.  Based on the graph minors of K{3,3} and K5 used to prove the correctness of the planarity algorithm, an analogous set of graph minors of K{2,3} and K4 were developed to help prove the correctness of the outerplanarity algorithm.  In turn, these minors were directly translatable into an implementation of an outerplanarity obstruction isolator, which find a subgraph homeomorphic to K{2,3} or K4 in a non-outerplanar graph.

From there, I began to study selected instances of the subgraph homeomorphism problem.  Specifically, I realized that the planarity and outerplanarity obstruction isolators could be augmented to find a subgraph homeomorphic to K{2,3} or K{3,3} by finding ways of ignoring the K4 and K5 obstructions unless they were entangled with the desired K{2,3} or K{3,3} obstructions.  At the time of the publication of my dissertation in 2001, I had determined how to find a subgraph homemorphic to K{2,3} in linear time, and I had determined how to find a subgraph homemorphic to K{3,3} in linear time if the input graph was triconnected, which matched the results of Asano and of Fellows and Kaschube.  

By 2003, I had implemented the additional planarity-related algorithms above and subjected them to rigorous testing similar to what I had done for the core planarity algorithm.  Along the way, I discovered an optimization for the K{3,3} subgraph homeomorphism algorithm so that it operated in linear time without requiring the input graph to be triconnected.  This result was superior to the works of Asano and of Fellows and Kaschube (by a constant factor) because it is a complex and costly (linear time) operation to isolate triconnected components of a graph and to reconstitute the original graph structure once a particular triconnected component is found to contain a K{3,3} homeomorph.

The last of the algorithms contained within Version 2.0 is a planar graph drawing algorithm.  A combinatorial planar embedding is an adjacency list representation in which the adjacency list of each vertex has a cyclic order that could be used to realize a planar drawing.  This is sometimes called a _rotation scheme_.  While a combinatorial planar embedding is an irrefutable certification of planarity and can be used by other algorithms for planar graphs, a further non-trivial algorithm is required to produce a drawing.  One type of drawing is called a _visibility representation_, which provides a vertical location and horizontal span for each vertex and a horizontal position and vertical span for each edge.  Prior algorithms for producing visibility representations are based on preprocessing the graph to produce an _st_-numbering.  This seemed problematic to me because, in my view, $st$-numbering itself more complicated than the whole planarity solution should be, and the structure and operation sequence imposed by  $st$-numbering contributes, in my view, to the complexity of the Lempel-Even-Cedarbaum planarity algorithm and to efficient operations on the Booth-Lueker PQ-trees.  The new algorithm in this project computes a visibility representation without perform a pre-processing step to determine an $st$-numbering.  Instead, it augments the core edge addition planarity algorithm  by collecting some additional information associated with operations of the core algorithm.  This information is then used in a post-processing step that performs a "sweep" method (inspired by the computational geometry method) on the combinatorial planar embedding to produce the visibility representation.  This method was reported at the International Symposium on Graph Drawing in 2005.

= An Extensible Implementation and Test Framework =

In order to create the original implementations of the various planarity-related algorithms, I would typically take a copy of Planarity Version 1.0 and augment as necessary to produce the new algorithm.  This was the most expedient means of producing new results in my spare time, which is when these algorithms and implementations are developed.  However, it became less and less tenable in the long term as I began to want to make improvements to the implementation of the core algorithm.  There are also more extension algorithms on the way.

One approach to creating an extensible framework was to port to C++.  The original implementation language for this project was selected after a long discussion with Wendy Myrvold, who convinced me that using straight C would avoid language features that added hidden costs to performance and would perhaps be more familiar to and easier to understand for a larger number of theoretical computer scientists and mathematicians. I still agree that was a good decision at the time.  In the future, C++ and Java versions are desirable, but the goal for version 2.0 was to create an extension framework that would allow my existing implementations of various extension algorithms to be unified without affecting their performance. This has now been [http://code.google.com/p/planarity/source/browse/#svn/tags/Version%202.0.0 done].